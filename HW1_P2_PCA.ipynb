{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPdjSMkV7ZVG"
   },
   "source": [
    "# HW 1 Problem 2: Principal Components Analysis (PCA)\n",
    "\n",
    "\n",
    "PCA is one of many techniques for **dimensionality reduction**. In neuroscience, one way it's useful is for understanding the activity within a large population of neurons.\n",
    "\n",
    "For example, one could use PCA to assess whether the population representation of a given stimulus set changes while the animal is attending to them vs. in a passive state. Or how the representation differs before and after learning as task that involves these stimuli.  \n",
    "\n",
    "The tool of PCA can be applied to neural spiking data with a number of different goals in mind. In the exercise below, you'll first reconsolidate the definition and utility of PCA. You'll then apply PCA to single-trial firing rate data for a large population. Then, you'll apply the same technique to the same data, but this time the time dimension is retained and we average over trials. In the latter case, the result looks kind of like PSTHs, but these traces reflect the population activity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRJ-3NCB7ZVH"
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTNOM4rb7ZVI"
   },
   "source": [
    "# Part A: Understanding PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AetQXPK-7ZVJ"
   },
   "source": [
    "## 2a. What is the goal of PCA?\n",
    "*Focus on the conceptual over the technical in your response.*\n",
    "\n",
    "[This tool](https://setosa.io/ev/principal-component-analysis/) might help you visualize what's going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8RdVbh77ZVJ"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\"> **Your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6JnvEbj7ZVJ"
   },
   "source": [
    "## 2b. List the mathematical steps of applying PCA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__CqUOEb7ZVJ"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\"> **Your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQrTLhuN7ZVK"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "# Part B: Explore neural data (coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7fR6R2q7ZVL",
    "outputId": "c3804747-4955-4244-f093-7f3b40ddb273"
   },
   "outputs": [],
   "source": [
    "# Run this code block first\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "\n",
    "# PREP DATA\n",
    "f = np.load('PCAdata_Steinmetz_VisCortex.npz', allow_pickle=True)\n",
    "spks = f['spks']\n",
    "trial_types = f['trial_types']\n",
    "tt_names = f['tt_names']\n",
    "tt_col = sns.color_palette('husl', len(tt_names))\n",
    "dt = 0.01  # time bin size 10 ms\n",
    "timevec = dt * np.arange(spks.shape[-1]) + dt - 0.5\n",
    "\n",
    "# FIGURE SETTINGS\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = [20, 4]\n",
    "rcParams['font.size'] = 12\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdIxkvMH7ZVM"
   },
   "source": [
    "## 2c. Build familiarity with data\n",
    "\n",
    "As always, you first want to understand the data. We're using a slice of data from [Steinmetz et al., 2019](https://www.nature.com/articles/s41586-019-1787-x).\n",
    "\n",
    "Briefly, in this experiment Steinmetz and colleagues presented visual grating stimuli to mice while recording from many brain regions. The data you are working with here were recorded in the visual cortical regions.\n",
    "\n",
    "Neural data is stored in the array **`spks`** with dimensions [neurons x trials x time bins]. Each time bin is 10ms, and the data from each trial represents a window starting 500ms before stimulus onset. Data is stored as spike count per bin.\n",
    "\n",
    "While spiking data was recorded, mice performed a behavioral task. [Figure 1](https://www.nature.com/articles/s41586-019-1787-x/figures/1) provides a visual depiction of the task. On each trial, two gratings were presented, one in the mouse's left visual vield and the other to the right. The gratings varied in contrast, and the mouse had to identify which one had the the higher contrast. It reported its decision by turning a small wheel to the right or left.\n",
    "\n",
    "**`trial_types`** contains an index corresponding to the stimulus presented on each trial. **`tt_names`** stores the string corresponding to each index.\n",
    "> **1 = 'left_incorrect'** : grating on the left had higher contrast but the mouse incorrectly chose right <br>\n",
    "> **2 = 'right_incorrect'** : grating on the right had higher contrast but the mouse incorrectly chose left  <br>\n",
    "> **3 = 'left_CORRECT'** : grating on the left had higher contrast and the mouse correctly chose left <br>\n",
    "> **4 = 'right_CORRECT'** : grating on the right had higher contrast and the mouse correctly chose right\n",
    "\n",
    "No-go trials in which the gratings had equal contrast were excluded from these data.\n",
    "\n",
    "<br>**Complete the code below, printing the relevant dimensions of key variables.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BHy4cq_87ZVM"
   },
   "outputs": [],
   "source": [
    "# Familiarize yourself with the data\n",
    "\n",
    "print('Shape of data array: {}'.format(...))\n",
    "print('Number of neurons: {}'.format(...))\n",
    "print('Number of trials: {}'.format(...))\n",
    "print('Number of time bins: {}'.format(...))\n",
    "print('Duration of each stimulus and response window, in seconds: {}'.format(...))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xl1b60tGXgm"
   },
   "source": [
    "## 2d. Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlctLGNsTT6b",
    "outputId": "e8a9fd59-e1b3-4f10-fe05-b22b6e419d2b"
   },
   "outputs": [],
   "source": [
    "# Plot PSTHs grouped by trial types\n",
    "# dont forget to label axes!\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=[9, 4])\n",
    "\n",
    "ax = axes[0]\n",
    "...\n",
    "ax.legend([tt_names[2], tt_names[3]], fontsize=12, loc='upper right')\n",
    "\n",
    "ax = axes[1]\n",
    "...\n",
    "ax.legend([tt_names[0], tt_names[1]], fontsize=12, loc='upper right');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY5oKlfb7ZVN"
   },
   "source": [
    "## 2e. Interpret data\n",
    "\n",
    "**i. Why are the PSTHs in the right panel noisier than those on the left?**\n",
    "\n",
    "**ii. In this session, do you think more neurons were recorded from the left or right hemisphere? Why?**\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ExA04DNHtEs"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\"> **Your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCuK5hZR7ZVN"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "# Background for Part C\n",
    "\n",
    "In Section C, we'll be using PCA to better understand the population's responses. There are many ways to use PCA to do this. The PCA process would be the same for each, but the input data (preparation steps) would differ. This **[image](https://drive.google.com/file/d/114sv9th-OPsj69PLsqMUVb-6waHo0PWP/view?usp=sharing)** created by Pietro Marchesi illustrates a variety of common preprocssing options.\n",
    "\n",
    "In Section C, we'll look at **time-averaged data**, meaning the firing rate/number of spikes per trial. (Called \"Trial-response\" in the image linked above.) With this approach, we lose any information in the temporal dynamics of the response, but we preserve sensitivity to trial-to-trial fluctuations in activity across the population. We'll first calculate PCA \"manually\", step by step using code, and then we'll compare the result to the output of sklearn's PCA function.\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBW8R94X7ZVN"
   },
   "source": [
    "\n",
    "# Part C: Manually apply PCA on time-averaged data<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmEhUMbq7ZVO"
   },
   "source": [
    "## 2f. Step 0: Prepare data (code)\n",
    "\n",
    "For this analysis, we want to investigate how the number of spikes emitted by each neuron varies across individual trials of each of the four types. Therefore, to prepare the data for PCA we need to average the response over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LBEbk4Nf7ZVO"
   },
   "outputs": [],
   "source": [
    "# # Step 0: Prepare data\n",
    "\n",
    "# First, we have to define the response window.\n",
    "resp_win = timevec>0\n",
    "\n",
    "# Then define our data matrix X. The dimensions of X should be [features x samples]\n",
    "X = spks... # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9y1pnDuI7ZVO"
   },
   "source": [
    "<br><br>\n",
    "## 2g. Step 1: Standardize data (code)\n",
    "\n",
    "Before beginning the PCA calculations, we want to center and scale the data so that all features (neurons, in this case) have an equal opportunity to determine latent features of the response. In other words, we want to transform the features such that the mean $≈$ 0 and the variance $≈$ 1. (This standardization is sometimes called the z-score.)\n",
    "\n",
    "If we skipped this step, the neurons with the highest firing rates would dominate the PCA result. There are philosophical discussions to be had, but typically neuroscientists would agree that a neuron whose FR changes from 0 to 10 sp/s when a stimulus begins is more important in the representation as a neuron whose FR goes from 45 sp/s to 55 sp/s, even though both show rate increases of 10 sp/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6rCBS5tc7ZVO"
   },
   "outputs": [],
   "source": [
    "# # Step 1: Standardize the data\n",
    "\n",
    "X += np.random.rand(X.shape[0],X.shape[1]) *  1e-9  # add a tiny bit of noise to avoid division by zero in next step\n",
    "\n",
    "Xz = ... # YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Note: we don't want NaNs in the result!\n",
    "if np.isnan(Xz).any():\n",
    "  print('WARNING: result contains NaNs.')\n",
    "else:\n",
    "  print('Result does not contain NaNs. All good to proceed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uH29GNGP7ZVP"
   },
   "source": [
    "<br><br>\n",
    "## 2h. Step 2: Compute covariance matrix (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S36KiGUm7ZVP"
   },
   "source": [
    "Now that we have a centered/standardized data matrix, which we call $Xz$, we can compute the covariance matrix by:\n",
    "<br><br>\n",
    "$$\n",
    "\\Sigma = \\frac{1}{n-1} X_z X_z^T\n",
    "$$\n",
    "<br>\n",
    "Do this manually, using linear algebra, instead of using a built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EYUBtwFw7ZVP"
   },
   "outputs": [],
   "source": [
    "# # Step 2: Compute covariance matrix\n",
    "\n",
    "cov_mat = # YOUR CODE HERE\n",
    "\n",
    "# Sanity check: what shape do we expect the covariance matrix to be?\n",
    "# It represents the degree to which the activity of each neuron covaries with the activity of the other neurons...\n",
    "print(cov_mat.shape)\n",
    "\n",
    "# The covariance matrix should be symmetric. Check that it is!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3NaGXBi7ZVP"
   },
   "source": [
    "<br><br>\n",
    "## Step 3: Eigendecomposition of covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrW3P6hJ7ZVP",
    "outputId": "d929cc03-c761-41e1-a633-392d77aa5aa0"
   },
   "outputs": [],
   "source": [
    "# Step 3: Eigendecomposition\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(cov_mat)\n",
    "\n",
    "# Sort eigenvalues and eigenvectors\n",
    "idx = eigenvalues.argsort()[::-1]\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:,idx]\n",
    "\n",
    "print('\\nTop 5 eigenvalues: \\n{}\\n'.format(eigenvalues[0:5,]))\n",
    "\n",
    "\n",
    "# Scree plot\n",
    "\n",
    "total_variance = np.sum(eigenvalues)\n",
    "explained_variance_ratio = eigenvalues / total_variance\n",
    "explained_variance_ratio = explained_variance_ratio[:15]\n",
    "print('Explained variance ratio by PC:', np.array2string(explained_variance_ratio, precision=3))\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(np.arange(1, len(explained_variance_ratio) + 1), explained_variance_ratio, '.-k')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.xticks(np.arange(1, len(explained_variance_ratio) + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25Squ0Dv7ZVQ"
   },
   "source": [
    "## 2i. Interpret\n",
    "\n",
    "**What information does the scree plot provide? What can you infer about these data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eq61Qtl77ZVQ"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\"> **Your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuWGdONP7ZVQ"
   },
   "source": [
    "<br><br>\n",
    "## 2j. Step 4: Project data into PC space (code)\n",
    "\n",
    "We now have a new orthonormal basis for our high dimensional data. The eigenvectors that correspond to the top PCs represent axes that capture the most variance in the data.\n",
    "\n",
    "Let's view our neural responses in a vector space defined by the first 2 PCs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qMaR7lYs7ZVQ"
   },
   "outputs": [],
   "source": [
    "# Step 4: Project data into a new vector space, C, composed of the top 2 eigenvectors\n",
    "\n",
    "C = eigenvectors[:,:3]  # define new orthonormal basis\n",
    "Xp = # YOUR CODE HERE   # project data into it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8UW4Q2xC8FI",
    "outputId": "e7dcd3d7-5a21-42ed-a053-3ca44a7eeebc"
   },
   "outputs": [],
   "source": [
    "# Plot projected data\n",
    "projections = [(0, 1), (1, 2), (0, 2)]\n",
    "fig, axes = plt.subplots(1, 3, figsize=[10, 4])\n",
    "for ax, proj in zip(axes, projections):\n",
    "    for t, t_type in enumerate(tt_names):\n",
    "      x = Xp[proj[0], trial_types==t+1]\n",
    "      y = Xp[proj[1], trial_types==t+1]\n",
    "      ax.scatter(x, y, color=tt_col[t], s=25, alpha=0.8)\n",
    "      ax.set_xlabel('PC {}'.format(proj[0]+1))\n",
    "      ax.set_ylabel('PC {}'.format(proj[1]+1))\n",
    "fig.legend(tt_names, fontsize=10, loc='outside upper right');\n",
    "fig.suptitle('Data projected into PC space');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUYMJh7D7ZVR"
   },
   "source": [
    "<br><br>\n",
    "## 2k. Interpret result\n",
    "\n",
    "**Based on this plot, what scientific observation(s) do you have about the dataset? Which PC (if any) has the best separation of left vs. right trials? Does the animal's behavioral response seem related to the population representation? Any other observations that you would want to follow up on, if this were your data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk9BPSbT7ZVR"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\"> **Your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrDb-Ocb7ZVR"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "# Part D: Perform PCA with built-in code\n",
    "\n",
    "Fortunately, you don't need to perform all of these steps manually each time. Instead, you can use scikit-learn's PCA class: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukXNekUw7ZVR",
    "outputId": "d99318d4-d514-4a37-9cab-c4ad00e76b30"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Use same input data as above: Xz\n",
    "pca = PCA(n_components=15, svd_solver='covariance_eigh')\n",
    "X_proj = pca.fit_transform(Xz.T).T\n",
    "\n",
    "# Check that dimensions match what you'd expect\n",
    "print('Shape of the input data: ',Xz.shape)\n",
    "print('Shape of the projected data: ',X_proj.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R66pv9067ZVR",
    "outputId": "6bec6134-c5c8-4b71-d837-e5554edec221"
   },
   "outputs": [],
   "source": [
    "# Inspect results\n",
    "print('\\nExplained variance ratio, manual:', np.array2string(explained_variance_ratio, precision=3))\n",
    "print('\\nExplained variance ratio, sklearn:', np.array2string(pca.explained_variance_ratio_, precision=3))\n",
    "print('\\n')\n",
    "\n",
    "# Scree plot (uncomment to show)\n",
    "plt.figure(figsize=(6, 4))  # Smaller plot size\n",
    "plt.plot(np.arange(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, '.-k')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Scree Plot')\n",
    "plt.xticks(np.arange(1, len(pca.explained_variance_ratio_) + 1))  # Integer x-axis ticks\n",
    "plt.show()\n",
    "print('\\n\\n')\n",
    "\n",
    "# Plot projected data\n",
    "projections = [(0, 1), (1, 2), (0, 2)]\n",
    "fig, axes = plt.subplots(1, 3, figsize=[10, 4])\n",
    "for ax, proj in zip(axes, projections):\n",
    "    for t, t_type in enumerate(tt_names):\n",
    "      x = X_proj[proj[0], trial_types==t+1]\n",
    "      y = X_proj[proj[1], trial_types==t+1]\n",
    "      ax.scatter(x, y, color=tt_col[t], s=25, alpha=0.8)\n",
    "      ax.set_xlabel('PC {}'.format(proj[0]+1))\n",
    "      ax.set_ylabel('PC {}'.format(proj[1]+1))\n",
    "fig.legend(tt_names, fontsize=10, loc='outside upper right');\n",
    "fig.suptitle('Data projected into PC space');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_vrinbG7ZVR"
   },
   "source": [
    "## 2l. Compare the results\n",
    "\n",
    "**Are the results the same? How/what did you inspect to determine if they are or not?**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbPhTSLn7ZVS"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\"> **Your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcvsnB8x7ZVU"
   },
   "source": [
    "<br><br>\n",
    "---\n",
    "\n",
    "# Optional challenges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5t0MuCCl7ZVU"
   },
   "source": [
    "**Was this exercise relatively easy for you? Choose a challenge below to tackle.**\n",
    "\n",
    "* Demonstrate why the spiking data should be standardized in order to obtain a reliable result.\n",
    "* In the population averaged PSTHs, there's a peak around 50 ms and a slower response spread around 300 ms. Is there evidence that these responses result from distinct populations of cells? Explain the logic and approach of how you could address this question and infer an answer. If you want to go further, execute the plan and describe what you find!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4uGNA1m7ZVU"
   },
   "source": [
    "<br><br><br>\n",
    "Credits: Data from Steinmetz et al, 2019 ([paper](https://www.nature.com/articles/s41586-019-1787-x); [data](https://figshare.com/articles/dataset/Dataset_from_Steinmetz_et_al_2019/9598406)). Image from [Pietro Marchesi's tutorial](https://pietromarchesi.net/pca-neural-data.html).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
